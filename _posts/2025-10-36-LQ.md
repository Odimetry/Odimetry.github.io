---
layout: post
title: "LQR / 선형 이차 제어기"
date: 2025-10-26 12:00 +0900
tags: [test]
---
Linear-quadratic regulator
===
The case where the system dynamics are described by a set of linear differential equations and the cost is described by a quadratic function is called the LQ problem. One of the main results in the theory is that the solution is provided by the linear-quadratic regulator (LQR), a feedback controller whose equations are given below. \\
LQR controllers possess inherent robustness with guaranteed gain and phase margin, and they also are part of the solution to the LQG (linear-quadratic-Gaussian) problem. Like the LQR problem itself, the LQG problem is one of the most fundamental problems in control theory.

Versions
===
**Commons**\\
$ \mathbf{x} \in \mathbb{R}^n, \mathbf{u} \in \mathbb{R}^m $
$F$ is the terminal cost matrix, $Q$ is the state cost matrix, $R$ is the control cost matrix, and $N$ is the cross-term(control and state) cost matrix.

**Finite-horizon, continuous-time**\\
For a continuous-time linear system, defined on $ t \in [t_0, t_1]$, described by: \\
$$
\dot{x} = Ax + Bu
$$ \\
Given a quadratic cost function for the system, defined as:
$$
J = x^{T}(t_1)F(t_1)x(t_1) + \int^{t_1}_{t_0} (x^{T}Qx + u^{T}Ru + 2x^{T}Nu) dt
$$

**Infinite-horizon, continuous-time**\\
A cost function defined as: \\
$$
J = \int^{\infty}_{0} (x^{T}Qx + u^{T}Ru + 2x^{T}Nu) dt
$$

**Finite-horizon, discrete-time**\\
For a discrete-time linear system described by:\\
$$
\mathbf{x_{k+1}} = A \mathbf{x_k} + B \mathbf{u_k}
$$\\
with a performance index defined as:\\
$$
J = \mathbf{x}^{T}_{H_{P}} Q_{H_{p}} \mathbf{x}_{H_{p}} + \Sigma^{H_{p}-1}_{k=0} (\mathbf{x}^T_k Q \mathbf{x}_k + \mathbf{u}^T_k R \mathbf{u}_k+2 \mathbf{x}^T_k N \mathbf{u}_k)
$$  \\
where $H_p$ is the time horizon.

**Infinite-horizon, discrete-time**\\
For a discrete-time linear system described by:\\
$$
\mathbf{x_{k+1}} = A \mathbf{x_k} + B \mathbf{u_k}
$$\\
with a performance index defined as:\\
$$
J = \Sigma^{\infty}_{k=0} (\mathbf{x}^T_k Q \mathbf{x}_k + \mathbf{u}^T_k R \mathbf{u}_k+2 \mathbf{x}^T_k N \mathbf{u}_k)
$$

**Constraints**\\
In practice, not all values of $\mathbf{x}_k, \mathbf{u}_k$ may be allowed. One common constraint is the linear one:
$$
C \mathbf{x} + D \mathbf{u} \leq e
$$ \\
The finite horizon version of this is a convex optimization problem, and so the problem is often solved repeatedly with a receding horizon. This is a form of model prediction control.

